import logging
import os
import threading

import torch
from torch import nn
from tqdm import tqdm

from classifier.conf.readConfig import Config
from classifier.data.loaders import getDataLoader
from classifier.engine.validator import validator, last_validator, predict_test
from classifier.nn.model import TextCNNModel
from classifier.utils.plotting import plot_loss_acc_curve
from classifier.utils.save import save_model, save_log

save_path = Config().save_path

def trainer(model_path=None):
    global loss, thread_save_best, net
    best_accuracy = 0
    if not os.path.exists(save_path):
        os.makedirs(save_path)
    item_list = os.listdir(save_path)
    s_p = save_path + '/run_' + str(len(item_list))    # è¿™æ˜¯æœ€ç»ˆçš„ä¿å­˜è·¯å¾„
    logging.info(f"è®­ç»ƒç»“æœä¿å­˜çš„è·¯å¾„ä¸º: " + s_p)

    loss_list = []
    accuracy_list = []

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    config = Config().config
    dataloader, embedding_matrix = getDataLoader(batch_size=config['batch_size'], mode='train', shuffle=True)

    val_dataloader = getDataLoader(batch_size=config['batch_size'], mode='val', shuffle=False)

    if model_path is None:
        net = TextCNNModel(embedding_matrix=embedding_matrix).to(device)
    else:
        net = torch.load(model_path).to(device)
    criterion = nn.BCEWithLogitsLoss().to(device)
    optimizer = torch.optim.Adam(net.parameters(), lr=config['learning_rate'])
    logging.info(f"å¼€å§‹è®­ç»ƒ... è®­ç»ƒæ€»è½®æ•°ä¸º: {config['epoch']}")
    for epoch in range(config['epoch']):
        logging.info(f"================================epoch:{epoch+1}/{config['epoch']}================================")
        for x, label in tqdm(dataloader, desc=f"Epoch {epoch+1}/{config['epoch']}"):
            x, label = x.to(device), label.to(device)
            pred = net(x)
            loss = criterion(pred, label)
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        logging.info(f"Loss: {loss.item():.8f}")

        acc = validator(net, val_dataloader, device)
        logging.info(f"Accuracy: {acc:.8f}")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹ ä»¥å¤šçº¿ç¨‹çš„æ–¹å¼ä¿å­˜ï¼ŒåŠ å¿«ç¨‹åºè¿è¡Œé€Ÿåº¦
        if acc > best_accuracy:
            best_accuracy = acc
            thread_save_best = threading.Thread(target=save_model, args=(net, "best.pt", s_p))
            thread_save_best.start()
        # ä¿å­˜æœ€åä¸€æ¬¡è®­ç»ƒçš„æ¨¡å‹
        thread = threading.Thread(target=save_model, args=(net, "last.pt", s_p))
        thread.start()
        loss_list.append(loss.item())
        accuracy_list.append(acc)
        save_log(s_p, f"epoch: {epoch+1} : loss: {loss.item():.8f} \t accuracy: {acc:.8f}")

    logging.info(f"ç­‰å¾…æ¨¡å‹å­˜å‚¨çº¿ç¨‹ä¿å­˜æ¨¡å‹å®Œæ¯•...")
    thread_save_best.join()
    # éªŒè¯ä¸€ä¸‹æœ€å¥½çš„æ¨¡å‹
    best_net_path = os.path.join(s_p, "weights", "best.pt")
    best_net = torch.load(best_net_path)  # è¯»å–æœ€å¥½çš„æ¨¡å‹
    logging.info(f"æ­£åœ¨éªŒè¯æœ€å¥½çš„æ¨¡å‹, æ¨¡å‹è·¯å¾„ä¸º: " + best_net_path )
    best_acc = last_validator(best_net, val_dataloader, device, s_p)
    logging.info(f"âœ¨éªŒè¯é›†ä¸Šæœ€ä¼˜å‡†ç¡®ç‡ä¸º: {best_acc:.8f}")
    save_log(s_p, f"âœ¨éªŒè¯é›†ä¸Šçš„æœ€ä¼˜å‡†ç¡®ç‡ä¸º: {best_acc:.8f}")
    save_log(s_p, f"ğŸˆæœ€ä¼˜æ¨¡å‹æƒé‡å·²ä¿å­˜è‡³: {best_net_path}")

    # å¯¹æµ‹è¯•é›†(test)è¿›è¡Œé¢„æµ‹å¹¶è¿›è¡Œå­˜å‚¨é¢„æµ‹å€¼
    test_dataloader = getDataLoader(config['batch_size'], shuffle=False, mode='test')
    predict_test(best_net, test_dataloader, device, s_p)
    logging.info(f"ğŸˆå¯¹æµ‹è¯•é›†é¢„æµ‹å®Œæ¯•, æ–‡ä»¶ä¿å­˜åœ¨: {s_p}")
    save_log(s_p, f"âœŒï¸æµ‹è¯•é›†çš„é¢„æµ‹ç»“æœå·²å­˜å‚¨åœ¨: {s_p}/test_predict(submission).txt")


    # æ‰§è¡Œç»“æŸåç»˜åˆ¶æŸå¤±å‡½æ•°æ›²çº¿ä»¥åŠå‡†ç¡®ç‡æ›²çº¿
    plot_loss_acc_curve(loss_list, accuracy_list, s_p)

